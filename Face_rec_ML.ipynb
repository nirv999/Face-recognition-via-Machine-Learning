{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning - Project: Face recognitions\n",
    "\n",
    "\n",
    "Submitted by: [Nir Vaknin & Slavik Lozver]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "from PIL import Image\n",
    "\n",
    "# Utility function to move the midpoint of a colormap to be around\n",
    "# the values of interest.\n",
    "\n",
    "#to print the heat map\n",
    "class MidpointNormalize(Normalize):\n",
    "\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image():  #loading all the data\n",
    "    path = 'att_faces'\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(40):\n",
    "        for j in range(10):\n",
    "            img = Image.open(os.path.join(path,'s'+str(i+1),str(j+1)+'.pgm'))\n",
    "            X.append(np.asarray(img,dtype=np.uint8).flatten())\n",
    "            y.append(i)\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------- SVM -----------------------------------------#\n",
    "def face_rec_svm(X,y,n_comp, gamma= 0.0001, C=100):\n",
    "    #spliting the training data and the testing data\n",
    "    X_trn, X_tst, y_trn, y_tst = train_test_split(X, y, test_size=0.2, random_state=42)  \n",
    "    \n",
    "    pca = PCA(n_components = n_comp, whiten=True) # reducing the dimension with the pca algorithm \n",
    "    X_trn_pca = pca.fit_transform(X_trn)\n",
    "    X_tst_pca= pca.transform(X_tst)\n",
    "    \n",
    "    eigenfaces = pca.components_.reshape((n_comp, 112, 92))  #saving the eigenfaces\n",
    "    \n",
    "   \n",
    "    sv = SVC(kernel='rbf',gamma = gamma, C=C)\n",
    "    sv.fit(X_trn_pca,y_trn) # fitting the training data \n",
    "\n",
    "    y_pred = sv.predict(X_tst_pca)\n",
    "    \n",
    "    return y_pred, y_tst, X_tst, eigenfaces\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_d(X):\n",
    "    pca = PCA(n_components = 400, whiten=True) # reducing the dimension with the pca algorithm \n",
    "    X_pca = pca.fit_transform(X)\n",
    "    var_arr = pca.explained_variance_  #variance array\n",
    "    best_d=0;\n",
    "    \n",
    "    for i in range (len(var_arr)-1):\n",
    "        if(var_arr[i] < var_arr[i+1]*1.005):  #the next variance is only 0.005% bigger then the current\n",
    "            break;\n",
    "    best_d=i+1\n",
    "    print(\"the best dimension is: \", best_d) #ploting the variance graph\n",
    "    plt.plot(var_arr)\n",
    "    plt.plot(best_d,var_arr[best_d], 'or')\n",
    "    plt.title(\"Variance as a function of Dimension\")\n",
    "    plt.ylabel('Variance')\n",
    "    plt.xlabel('Dimension')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    return best_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = read_image() #reading the data\n",
    "\n",
    "def mis_count_svm(X,y, min_d,): #countin the misclassifications\n",
    "    r,comp =X.shape\n",
    "    dim = [2, min_d ,300]\n",
    "    mis = np.zeros(3) # count the missclassifications\n",
    "    \n",
    "    for i in range(3):\n",
    "        d=dim[i]\n",
    "        c, gamma = find_best_para(X,y,d,0)   # finding the best c, and gamma for current dimension\n",
    "        y_pred, y_tst, X_tst, eigenfaces= face_rec_svm(X,y,d, gamma, c)\n",
    "        for j in range(len(y_tst)):\n",
    "            if (y_pred[j]!=y_tst[j]):\n",
    "                mis[i]+=1\n",
    "        print(\"dimension: \", d)\n",
    "        print(\"misclassifications: \", mis[i])\n",
    "min_d=find_best_d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## finding the best gamma and C\n",
    "def find_best_para(X,y,min_d, plot=1):\n",
    "    pca = PCA(n_components = min_d, whiten=True) # reducing the dimension with the pca algorithm \n",
    "    X_pca = pca.fit_transform(X)\n",
    "    C_range = np.logspace(-2, 10, 13)\n",
    "    gamma_range = np.logspace(-9, 3, 13)\n",
    "    param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "    \n",
    "    cv = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=42)\n",
    "    grid = GridSearchCV(SVC(kernel='rbf'), param_grid=param_grid, cv=cv)\n",
    "    grid.fit(X_pca, y)\n",
    "    \n",
    "    print(\"The best parameters are %s with a score of %0.2f\"\n",
    "          % (grid.best_params_, grid.best_score_))\n",
    "\n",
    "    scores = grid.cv_results_['mean_test_score'].reshape(len(C_range),  # for ploting the score in the heat map\n",
    "                                                         len(gamma_range)) \n",
    "\n",
    "    #plotting an heat map of the parameters\n",
    "    if(plot ==1):\n",
    "        plt.figure(figsize=(8, 6))                                 \n",
    "        plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "        plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot,\n",
    "                   norm=MidpointNormalize(vmin=0.2, midpoint=0.92))\n",
    "        plt.xlabel('gamma')\n",
    "        plt.ylabel('C')\n",
    "        plt.colorbar()\n",
    "        plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "        plt.yticks(np.arange(len(C_range)), C_range)\n",
    "        plt.title('Validation accuracy')\n",
    "        plt.show()\n",
    "\n",
    "    return grid.best_estimator_.C, grid.best_estimator_.gamma\n",
    "\n",
    "best_C , best_gamma = find_best_para(X,y,min_d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the eigenfaces\n",
    "mis_count_svm(X,y,min_d) # counting the misclassification of each dimension\n",
    "y_pred, y_tst, X_tst,eigenfaces = face_rec_svm(X,y,min_d, best_C, best_gamma)\n",
    "h=112\n",
    "w=92\n",
    "plt.figure(figsize=(12,10))\n",
    "print(\"the eigen-faces: \")\n",
    "for i in range(50):  # ploting the 50 first eigen faces\n",
    "        plt.subplot(5, 10, i + 1)\n",
    "        plt.imshow(eigenfaces[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function that prints the image of the predicted randomely face and all his rest faces in the test data\n",
    "def face_check(X_tst, y_pred, y_tst):  \n",
    "    num = np.random.randint(0,len(y_pred))  # random face \n",
    "    plt.figure(figsize=(5,3))\n",
    "    print(\"predicted: (random)\")\n",
    "    plt.imshow(X_tst[num].reshape((h, w)), cmap=plt.cm.gray)\n",
    "    plt.show()\n",
    "    print(\"all faces of the predicted person: (in test data)\")\n",
    "    j=0\n",
    "    plt.figure(figsize=(12,10))\n",
    "    for i in range(len(y_tst)):   \n",
    "        if(y_pred[num]== y_tst[i]): # showing the rest faces of the same person that we predicted \n",
    "            plt.subplot(3, 10, j + 1)\n",
    "            plt.imshow(X_tst[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "            plt.xticks(())\n",
    "            plt.yticks(())\n",
    "            j+=1\n",
    "face_check(X_tst, y_pred, y_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------- LogisticRegression -----------------------------------------#\n",
    "def face_rec_log_reg(X,y,n_comp,c=1.0):\n",
    "    X_trn, X_tst, y_trn, y_tst = train_test_split(X, y, test_size=0.20, random_state=42)  \n",
    "    \n",
    "    pca = PCA(n_components = n_comp, whiten=True) # reducing the dimension with the pca algorithm \n",
    "    X_trn_pca = pca.fit_transform(X_trn)\n",
    "    X_tst_pca= pca.transform(X_tst)\n",
    "    eigenfaces = pca.components_.reshape((n_comp, 112, 92))  #saving the eigenfaces\n",
    "    \n",
    "    logreg= LogisticRegression(C=c)\n",
    "    logreg.fit(X_trn_pca,y_trn)\n",
    "    y_pred = logreg.predict(X_tst_pca)\n",
    "    \n",
    "    return y_pred, y_tst, X_tst, eigenfaces\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mis_count_log(X,y, min_d,): #countin the misclassifications\n",
    "    r,comp =X.shape\n",
    "    dim = [2, min_d ,300]\n",
    "    mis = np.zeros(3)\n",
    "    \n",
    "    for i in range(3):\n",
    "        d=dim[i]\n",
    "        y_pred, y_tst, X_tst, eigenfaces= face_rec_log_reg(X,y,d)\n",
    "        for j in range(len(y_tst)):\n",
    "            if (y_pred[j]!=y_tst[j]):\n",
    "                mis[i]+=1\n",
    "        print(\"dimension: \", d)\n",
    "        print(\"misclassifications: \", mis[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_count_log(X,y,min_d)\n",
    "\n",
    "y_pred, y_tst, X_tst,eigenfaces_log = face_rec_log_reg(X,y,min_d) \n",
    "\n",
    "h=112\n",
    "w=92\n",
    "plt.figure(figsize=(12,10))\n",
    "print(\"the 50 first eigen-faces: \")\n",
    "for i in range(50):  # ploting the eigen faces\n",
    "        plt.subplot(5, 10, i + 1)\n",
    "        plt.imshow(eigenfaces_log[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
